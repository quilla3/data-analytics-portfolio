/* ============================================
(1) Open Terminal window and navigate to a folder where a file sales.txt is stored.
(2) Use cat command to list the contents of a file sales.txt in Terminal window.
============================================ */

bigdata@bigdata-VirtualBox:~$ cd Desktop
bigdata@bigdata-VirtualBox:~/Desktop$ cat sales.txt
bolt 2 25
washer 3 8
screw 7 20
nail 5 10
screw 7 2
bolt 2 20
bolt 2 30
drill 10 5
washer 3 8

/* ============================================
(3) Upload a file sales.txt to HDFS. Location of the file in HDFS is up to you.
============================================ */

bigdata@bigdata-VirtualBox:~/Desktop$ hdfs dfs -put sales.txt

/* ============================================
(4) Navigate to a folder where a file solution3.py is stored.
(5) Use cat command to list the contents of a file solution3.py in Terminal window.
============================================ */

bigdata@bigdata-VirtualBox:~/Desktop$ cat solution3.py
#!/usr/bin/env python3

import sys
	 
def filter(givenValue):
	for line in sys.stdin:
		line = line.strip()
		if not line:
			continue
		item, price, units = line.split(' ', 2)
		price = float(price)
		units = int(units)
		if (price * units > givenValue):
			print ('%s\t%s' % (item, price*units))

if __name__ == "__main__":
	givenValue = float(sys.argv[1])
	filter(givenValue)

/* ============================================
(6) Use chmod command to change user's access permission to a file solution3.py.
(7) Process a program in solution3.py with Hadoop streaming feature.
============================================ */

bigdata@bigdata-VirtualBox:~/Desktop$ chmod u+x solution3.py
bigdata@bigdata-VirtualBox:~/Desktop$ mapred streaming -D mapred.reduce.tasks=0 -input sales.txt -output output -mapper "python3 solution3.py 40"
2024-08-07 15:21:57,825 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-08-07 15:21:57,903 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-08-07 15:21:57,904 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2024-08-07 15:21:57,918 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2024-08-07 15:21:58,118 INFO mapred.FileInputFormat: Total input files to process : 1
2024-08-07 15:21:58,173 INFO mapreduce.JobSubmitter: number of splits:1
2024-08-07 15:21:58,199 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
2024-08-07 15:21:58,277 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1178429838_0001
2024-08-07 15:21:58,277 INFO mapreduce.JobSubmitter: Executing with tokens: []
2024-08-07 15:21:58,397 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2024-08-07 15:21:58,398 INFO mapreduce.Job: Running job: job_local1178429838_0001
2024-08-07 15:21:58,400 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2024-08-07 15:21:58,400 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2024-08-07 15:21:58,404 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-08-07 15:21:58,405 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-08-07 15:21:58,450 INFO mapred.LocalJobRunner: Waiting for map tasks
2024-08-07 15:21:58,461 INFO mapred.LocalJobRunner: Starting task: attempt_local1178429838_0001_m_000000_0
2024-08-07 15:21:58,484 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2024-08-07 15:21:58,484 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2024-08-07 15:21:58,508 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2024-08-07 15:21:58,516 INFO mapred.MapTask: Processing split: hdfs://127.0.0.1:9000/user/bigdata/sales.txt:0+94
2024-08-07 15:21:58,547 INFO mapred.MapTask: numReduceTasks: 0
2024-08-07 15:21:58,603 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/bin/python3, solution3.py, 40]
2024-08-07 15:21:58,604 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
2024-08-07 15:21:58,607 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2024-08-07 15:21:58,608 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
2024-08-07 15:21:58,608 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
2024-08-07 15:21:58,608 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2024-08-07 15:21:58,608 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2024-08-07 15:21:58,617 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
2024-08-07 15:21:58,617 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2024-08-07 15:21:58,617 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2024-08-07 15:21:58,617 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2024-08-07 15:21:58,618 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2024-08-07 15:21:58,621 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
2024-08-07 15:21:58,688 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]
2024-08-07 15:21:58,689 INFO streaming.PipeMapRed: Records R/W=9/1
2024-08-07 15:21:58,691 INFO streaming.PipeMapRed: MRErrorThread done
2024-08-07 15:21:58,691 INFO streaming.PipeMapRed: mapRedFinished
2024-08-07 15:21:58,692 INFO mapred.LocalJobRunner: 
2024-08-07 15:21:58,741 INFO mapred.Task: Task:attempt_local1178429838_0001_m_000000_0 is done. And is in the process of committing
2024-08-07 15:21:58,743 INFO mapred.LocalJobRunner: 
2024-08-07 15:21:58,743 INFO mapred.Task: Task attempt_local1178429838_0001_m_000000_0 is allowed to commit now
2024-08-07 15:21:58,763 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1178429838_0001_m_000000_0' to hdfs://127.0.0.1:9000/user/bigdata/output
2024-08-07 15:21:58,764 INFO mapred.LocalJobRunner: Records R/W=9/1
2024-08-07 15:21:58,764 INFO mapred.Task: Task 'attempt_local1178429838_0001_m_000000_0' done.
2024-08-07 15:21:58,767 INFO mapred.Task: Final Counters for attempt_local1178429838_0001_m_000000_0: Counters: 21
	File System Counters
		FILE: Number of bytes read=141426
		FILE: Number of bytes written=789663
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=94
		HDFS: Number of bytes written=53
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=9
		Map output records=5
		Input split bytes=96
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=32571392
	File Input Format Counters 
		Bytes Read=94
	File Output Format Counters 
		Bytes Written=53
2024-08-07 15:21:58,768 INFO mapred.LocalJobRunner: Finishing task: attempt_local1178429838_0001_m_000000_0
2024-08-07 15:21:58,768 INFO mapred.LocalJobRunner: map task executor complete.
2024-08-07 15:21:59,401 INFO mapreduce.Job: Job job_local1178429838_0001 running in uber mode : false
2024-08-07 15:21:59,403 INFO mapreduce.Job:  map 100% reduce 0%
2024-08-07 15:21:59,407 INFO mapreduce.Job: Job job_local1178429838_0001 completed successfully
2024-08-07 15:21:59,422 INFO mapreduce.Job: Counters: 21
	File System Counters
		FILE: Number of bytes read=141426
		FILE: Number of bytes written=789663
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=94
		HDFS: Number of bytes written=53
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=9
		Map output records=5
		Input split bytes=96
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=32571392
	File Input Format Counters 
		Bytes Read=94
	File Output Format Counters 
		Bytes Written=53
2024-08-07 15:21:59,428 INFO streaming.StreamJob: Output directory: output

/* ============================================
(8) Display the results stored by your program in HDFS.
============================================ */

bigdata@bigdata-VirtualBox:~/Desktop$ hdfs dfs -cat output/p*
bolt	50.0
screw	140.0
nail	50.0
bolt	60.0
drill	50.0
